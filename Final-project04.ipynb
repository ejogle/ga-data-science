{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n"
     ]
    }
   ],
   "source": [
    "dta = pd.read_csv(\"Bank Marketing FULL.csv\")\n",
    "dta.dropna()\n",
    "\n",
    "print dta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 65)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(dta)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[df.pdays == 999, 'pdays'] = 0\n",
    "# 'pdays' = 999 means the client was not previously contacted about a campaign\n",
    "# all 999 values were changed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 54)\n",
      "Index([u'age', u'campaign', u'pdays', u'previous', u'emp.var.rate',\n",
      "       u'cons.price.idx', u'cons.conf.idx', u'euribor3m', u'nr.employed',\n",
      "       u'job_admin.', u'job_blue-collar', u'job_entrepreneur',\n",
      "       u'job_housemaid', u'job_management', u'job_retired',\n",
      "       u'job_self-employed', u'job_services', u'job_student',\n",
      "       u'job_technician', u'job_unknown', u'marital_divorced',\n",
      "       u'marital_married', u'marital_unknown', u'education_basic.4y',\n",
      "       u'education_basic.6y', u'education_basic.9y', u'education_illiterate',\n",
      "       u'education_professional.course', u'education_university.degree',\n",
      "       u'education_unknown', u'default_unknown', u'default_yes',\n",
      "       u'housing_unknown', u'housing_yes', u'loan_unknown', u'loan_yes',\n",
      "       u'contact_cellular', u'month_apr', u'month_aug', u'month_dec',\n",
      "       u'month_jul', u'month_jun', u'month_mar', u'month_nov', u'month_oct',\n",
      "       u'month_sep', u'day_of_week_mon', u'day_of_week_thu',\n",
      "       u'day_of_week_tue', u'day_of_week_wed', u'poutcome_nonexistent',\n",
      "       u'poutcome_success', u'y_yes', u'intercept'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# dropping default categories for new dummy data set\n",
    "col_drop = ['duration',\n",
    "        'job_unemployed',\n",
    "        'marital_single',\n",
    "        'education_high.school',\n",
    "        'default_no',\n",
    "        'housing_no',\n",
    "        'loan_no',\n",
    "        'contact_telephone',\n",
    "        'month_may', # range of contact months was March through December, most contact occurred during May.\n",
    "        'day_of_week_fri',\n",
    "        'poutcome_failure',\n",
    "        'y_no']\n",
    "dta_dummies = df.drop(df[col_drop], axis=1)\n",
    "# 'y_yes' is outcome variable\n",
    "\n",
    "dta_dummies.dropna()\n",
    "dta_dummies['intercept'] = 1.0\n",
    "print dta_dummies.shape\n",
    "print dta_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_cols = dta_dummies.columns[:52]\n",
    "#print train_cols\n",
    "\n",
    "train_cols = ['age',\n",
    "              'campaign',\n",
    "              'pdays',\n",
    "              'previous',\n",
    "              'emp.var.rate',\n",
    "              'cons.price.idx',\n",
    "              'cons.conf.idx',\n",
    "              'euribor3m',\n",
    "              'nr.employed',\n",
    "              'job_admin.',\n",
    "              'job_blue-collar',\n",
    "              'job_entrepreneur',\n",
    "              'job_housemaid',\n",
    "              'job_management',\n",
    "              'job_retired',\n",
    "              'job_self-employed',\n",
    "              'job_services',\n",
    "              'job_student',\n",
    "              'job_technician',\n",
    "              'job_unknown',\n",
    "              'marital_married',\n",
    "              'marital_divorced',\n",
    "              'marital_unknown',\n",
    "              'education_basic.4y',\n",
    "              'education_basic.6y',\n",
    "              'education_basic.9y',\n",
    "              'education_illiterate',\n",
    "              'education_professional.course',\n",
    "              'education_university.degree',\n",
    "              'education_unknown',\n",
    "              'default_yes',\n",
    "              'default_unknown',\n",
    "              'housing_yes',\n",
    "              'housing_unknown',\n",
    "              'loan_yes',\n",
    "              'loan_unknown',\n",
    "              'contact_cellular',\n",
    "              'month_mar',\n",
    "              'month_apr',\n",
    "              'month_jun',\n",
    "              'month_jul',\n",
    "              'month_aug',\n",
    "              'month_sep',\n",
    "              'month_oct',\n",
    "              'month_nov',\n",
    "              'month_dec',\n",
    "              'day_of_week_mon',\n",
    "              'day_of_week_tue',\n",
    "              'day_of_week_wed',\n",
    "              'day_of_week_thu',\n",
    "              'poutcome_success',\n",
    "              'poutcome_nonexistent',\n",
    "              'intercept']\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEATURE SELECTION prior to LR, regularization afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive Feature Selection with Cross Validation\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X = dta_dummies[train_cols]\n",
    "y = dta_dummies['y_yes']\n",
    " \n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(y, 5),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.savefig('RFECV.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic LR model\n",
    "model = LogisticRegression()\n",
    "model = model.fit(dta_dummies[train_cols], dta_dummies['y_yes'])\n",
    "\n",
    "print model.score(dta_dummies[train_cols], dta_dummies['y_yes'])\n",
    "print dta_dummies['y_yes'].mean()\n",
    "# Approx. 90% accuracy without optimization or cross validation, although with only ~11% of all clients having \n",
    "# purchased term deposits we could still have almost 90% accuracy by always predicting \"No\".\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(dta_dummies[train_cols], np.transpose(model.coef_)))\n",
    "#    Examining the coefficients, we see that increases in the number of contacts performed for a client both during \n",
    "# and prior to the current campaign (the 'campaign' and 'previous' variables) correspond with decreases in the\n",
    "# likelihood of purchase. Increases in the employment variation rate and Euribor 3 month rate (the reference interest\n",
    "# rate published by the European Banking Federation) also logically correspond with decreases in purchase likelihood. \n",
    "# Demographically, customers with varying levels of \"basic\" education were less likely to purchase deposits as were\n",
    "# customers with either personal or home loans or credit in default. The only professions with increased likelihood of\n",
    "# purchase were retirees, students, and technicians. Obviously if the outcome of the previous marketing campaign was\n",
    "# a success, the client was more likely to purchase a deposit as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Evaluation with Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dta_dummies[train_cols], \n",
    "    dta_dummies['y_yes'], \n",
    "    test_size=0.4, random_state=0)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "eval_model = LogisticRegression()\n",
    "print eval_model.fit(X_train, y_train)\n",
    "print eval_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedTEST = eval_model.predict(X_test)\n",
    "predictedTRAIN = eval_model.predict(X_train)\n",
    "probs = eval_model.predict_proba(X_test) \n",
    "\n",
    "# The training and test sets performed about the same, ~89% accuracy, though the test set was 0.001 higher.\n",
    "print eval_model.score(X_test, y_test)\n",
    "print metrics.accuracy_score(y_test, predictedTEST)  \n",
    "print metrics.classification_report(y_test, predictedTEST)\n",
    "print metrics.classification_report(y_train, predictedTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for test set with corresponding AUC score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictedTEST)\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion Matrix, without Normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)\n",
    "plt.savefig('CM.pdf')\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized Confusion Matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized Confusion Matrix')\n",
    "plt.savefig('CMnorm.pdf')\n",
    "plt.show()\n",
    "\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ROC curve with cross validation\n",
    "cv = StratifiedKFold(y_test, n_folds=10)\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    probas_ = eval_model.fit(X_train, y_train).predict_proba(X_test)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Bank Marketing ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, \n",
    "                         dta_dummies[train_cols], \n",
    "                         dta_dummies['y_yes'], \n",
    "                         scoring='accuracy', cv=8)\n",
    "print scores.mean()\n",
    "# With cross validation we see the model performing at 82% accuracy, which is pretty good in the employment \n",
    "# of direct marketing where costs of missclassification (calling the wrong person) are low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With 5 folds the mean AUC is 0.77, a score which can definitely be improved through increased \n",
    "# analysis of the actual responders and the respective attributes that had the strongest affect on the successful\n",
    "# outcome. It should be noted that all folds had the same AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "clf = Ridge(alpha=0.2)\n",
    "print clf.fit(dta_dummies[train_cols], dta_dummies['y_yes'])\n",
    "print clf.score(dta_dummies[train_cols], dta_dummies['y_yes'])\n",
    "#RidgeClassifier(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, \n",
    "                #max_iter=None, tol=0.001, class_weight=None, solver='auto', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "clf = Lasso(alpha=0.2)\n",
    "print clf.fit(dta_dummies[train_cols], dta_dummies['y_yes'])\n",
    "print clf.score(dta_dummies[train_cols], dta_dummies['y_yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
